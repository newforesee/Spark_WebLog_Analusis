2018-12-06 09:57:08,964-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 09:57:09,465-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 09:57:09,648-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 09:57:09,673-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 09:57:09,673-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 09:57:09,674-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 09:57:09,675-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 09:57:09,675-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 09:57:10,020-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51450.
2018-12-06 09:57:10,044-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 09:57:10,067-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 09:57:10,071-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 09:57:10,071-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 09:57:10,081-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-aac53bfb-6011-452f-b5cf-31eb42006196
2018-12-06 09:57:10,135-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 09:57:10,193-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 09:57:10,325-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2067ms
2018-12-06 09:57:10,408-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 09:57:10,424-[TS] INFO main org.spark_project.jetty.server.Server - Started @2168ms
2018-12-06 09:57:10,445-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@3bedc33d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 09:57:10,445-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 09:57:10,468-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cbee484{/jobs,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,468-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,469-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,470-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,471-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,471-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,472-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,474-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,475-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,476-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,476-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,477-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,479-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,480-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,480-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,481-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,482-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,483-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,484-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,485-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,494-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/static,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,495-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,496-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60cf80e7{/api,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,496-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,497-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 09:57:10,499-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 09:57:10,595-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 09:57:10,618-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51452.
2018-12-06 09:57:10,618-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51452
2018-12-06 09:57:10,620-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 09:57:10,649-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51452, None)
2018-12-06 09:57:10,653-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51452 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51452, None)
2018-12-06 09:57:10,657-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51452, None)
2018-12-06 09:57:10,657-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51452, None)
2018-12-06 09:57:10,859-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f5b5ca4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:12,693-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 09:57:12,694-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 09:57:12,704-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL,null,AVAILABLE,@Spark}
2018-12-06 09:57:12,704-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64387c17{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:12,705-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 09:57:12,706-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e62ead7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 09:57:12,709-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60ed12e8{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 09:57:13,334-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 09:57:13,571-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 09:57:13,888-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 09:57:13,900-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 09:59:53,909 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 09:59:53,909-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 09:59:54,429 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 09:59:54,429-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 09:59:54,640 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 09:59:54,640-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 09:59:54,663 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 09:59:54,663-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 09:59:54,664 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 09:59:54,664-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 09:59:54,664 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 09:59:54,664-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 09:59:54,665 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 09:59:54,665-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 09:59:54,665 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 09:59:54,665-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 09:59:54,929 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51672.
2018-12-06 09:59:54,929-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51672.
2018-12-06 09:59:54,946 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 09:59:54,946-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 09:59:54,960 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 09:59:54,960-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 09:59:54,962 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 09:59:54,962-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 09:59:54,963 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 09:59:54,963-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 09:59:54,969 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e7e42ffb-2d0c-4fbb-9f5d-03477f988950
2018-12-06 09:59:54,969-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e7e42ffb-2d0c-4fbb-9f5d-03477f988950
2018-12-06 09:59:55,013 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 09:59:55,013-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 09:59:55,065 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 09:59:55,065-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 09:59:55,215 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2123ms
2018-12-06 09:59:55,215-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2123ms
2018-12-06 09:59:55,293 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 09:59:55,293-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 09:59:55,309 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2220ms
2018-12-06 09:59:55,309-[TS] INFO main org.spark_project.jetty.server.Server - Started @2220ms
2018-12-06 09:59:55,328 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@59305efc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 09:59:55,328-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@59305efc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 09:59:55,330 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 09:59:55,330-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 09:59:55,357 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,357-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,358 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,358-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,359 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,359-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,360 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,360-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,361 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,361-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,362 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,362-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,363 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,363-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,365 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,365-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,366 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,366-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,367 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,367-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,368 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,368-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,370 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,370-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,371 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,371-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,373 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,373-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,374 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,374-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,375 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,375-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,376 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,376-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,377 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,377-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,378 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,378-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,380 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,380-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,391 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,391-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,392 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,392-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,394 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,394-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,395 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,395-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,396 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,396-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,398 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 09:59:55,398-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 09:59:55,505 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 09:59:55,505-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 09:59:55,532 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51674.
2018-12-06 09:59:55,532-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51674.
2018-12-06 09:59:55,534 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51674
2018-12-06 09:59:55,534-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51674
2018-12-06 09:59:55,536 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 09:59:55,536-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 09:59:55,559 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,559-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,563 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51674 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,563-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51674 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,565 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,565-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,565 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,565-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51674, None)
2018-12-06 09:59:55,732 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:55,732-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,199 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 09:59:57,199-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 09:59:57,201 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 09:59:57,201-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 09:59:57,210 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,210-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,211 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,211-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,212 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,212-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,212 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,212-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,214 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,214-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 09:59:57,678 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 09:59:57,678-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 09:59:57,834 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 09:59:57,834-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 09:59:58,089 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 09:59:58,089-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 09:59:58,104 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 09:59:58,104-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 10:01:34,165 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 10:01:34,165-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 10:03:00,113 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 10:03:00,113-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 10:03:00,601 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 10:03:00,601-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 10:03:00,768 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 10:03:00,768-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 10:03:00,790 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 10:03:00,790-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 10:03:00,791 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 10:03:00,791-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 10:03:00,792 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 10:03:00,792-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 10:03:00,792 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 10:03:00,792-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 10:03:00,793 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 10:03:00,793-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 10:03:01,097 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51935.
2018-12-06 10:03:01,097-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51935.
2018-12-06 10:03:01,113 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 10:03:01,113-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 10:03:01,129 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 10:03:01,129-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 10:03:01,131 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 10:03:01,131-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 10:03:01,131 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 10:03:01,131-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 10:03:01,138 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a256e348-66c3-40f1-9ff7-45f6ff144c9c
2018-12-06 10:03:01,138-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a256e348-66c3-40f1-9ff7-45f6ff144c9c
2018-12-06 10:03:01,185 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 10:03:01,185-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 10:03:01,241 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 10:03:01,241-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 10:03:01,331 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1917ms
2018-12-06 10:03:01,331-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1917ms
2018-12-06 10:03:01,392 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 10:03:01,392-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 10:03:01,408 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1995ms
2018-12-06 10:03:01,408-[TS] INFO main org.spark_project.jetty.server.Server - Started @1995ms
2018-12-06 10:03:01,433 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@45f9815d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 10:03:01,433-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@45f9815d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 10:03:01,433 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 10:03:01,433-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 10:03:01,459 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,459-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,459 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,459-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,460 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,460-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,461 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,461-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,462 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,462-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,463 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,463-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,464 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,464-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,465 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,465-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,466 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,466-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,467 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,467-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,468 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,468-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,469 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,469-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,470 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,470-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,471 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,471-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,471 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,471-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,472 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,472-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,473 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,473-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,474 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,474-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,475 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,475-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,476 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,476-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,485 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,485-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,487 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,487-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,489 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,489-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,490 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,490-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,491 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,491-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,493 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 10:03:01,493-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 10:03:01,584 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 10:03:01,584-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 10:03:01,610 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51937.
2018-12-06 10:03:01,610-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51937.
2018-12-06 10:03:01,610 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51937
2018-12-06 10:03:01,610-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51937
2018-12-06 10:03:01,611 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 10:03:01,611-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 10:03:01,636 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,636-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,640 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51937 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,640-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51937 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,643 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,643-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,644 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,644-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51937, None)
2018-12-06 10:03:01,821 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:01,821-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,309 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 10:03:03,309-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 10:03:03,311 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 10:03:03,311-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 10:03:03,319 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,319-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,320 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,320-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,321 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,321-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,321 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,321-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,323 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,323-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 10:03:03,860 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 10:03:03,860-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 10:03:04,054 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 10:03:04,054-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 10:03:04,473 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 10:03:04,473-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 10:03:04,494 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 10:03:04,494-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 10:03:18,613 [dispatcher-event-loop-1] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (104 KB). The maximum recommended task size is 100 KB.
2018-12-06 10:03:18,613-[TS] WARN dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (104 KB). The maximum recommended task size is 100 KB.
2018-12-06 10:52:27,924 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 10:52:27,924-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 10:52:28,504 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 10:52:28,504-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 10:52:28,675 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 10:52:28,675-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 10:52:28,695 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 10:52:28,695-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 10:52:28,695 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 10:52:28,695-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 10:52:28,696 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 10:52:28,696-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 10:52:28,696 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 10:52:28,696-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 10:52:28,697 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 10:52:28,697-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 10:52:28,955 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 55760.
2018-12-06 10:52:28,955-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55760.
2018-12-06 10:52:28,974 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 10:52:28,974-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 10:52:28,989 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 10:52:28,989-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 10:52:28,991 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 10:52:28,991-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 10:52:28,992 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 10:52:28,992-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 10:52:29,000 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6e7c851b-0cb7-4385-88b4-0dfd7cca00de
2018-12-06 10:52:29,000-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6e7c851b-0cb7-4385-88b4-0dfd7cca00de
2018-12-06 10:52:29,053 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 10:52:29,053-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 10:52:29,109 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 10:52:29,109-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 10:52:29,201 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2058ms
2018-12-06 10:52:29,201-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2058ms
2018-12-06 10:52:29,264 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 10:52:29,264-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 10:52:29,280 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2138ms
2018-12-06 10:52:29,280-[TS] INFO main org.spark_project.jetty.server.Server - Started @2138ms
2018-12-06 10:52:29,294 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 10:52:29,294-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 10:52:29,295 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 10:52:29,295-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 10:52:29,314 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,314-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,315 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,315-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,315 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,315-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,316 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,316-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,317 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,317-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,318 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,318-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,318 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,318-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,320 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,320-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,321 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,321-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,321 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,321-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,322 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,322-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,323 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,323-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,324 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,324-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,325 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,325-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,326 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,326-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,327 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,327-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,328 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,328-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,328 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,328-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,329 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,329-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,329 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,329-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,335 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,335-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,336 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,336-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,338 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,338-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,339 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,339-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,341 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,341-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,343 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 10:52:29,343-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 10:52:29,414 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 10:52:29,414-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 10:52:29,434 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55762.
2018-12-06 10:52:29,434-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55762.
2018-12-06 10:52:29,435 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:55762
2018-12-06 10:52:29,435-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:55762
2018-12-06 10:52:29,436 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 10:52:29,436-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 10:52:29,460 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,460-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,464 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:55762 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,464-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:55762 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,466 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,466-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,466 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,466-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 55762, None)
2018-12-06 10:52:29,644 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:29,644-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,066 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 10:52:31,066-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 10:52:31,066 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 10:52:31,066-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 10:52:31,072 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,072-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,072 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,072-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,073 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,073-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,074 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,074-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,075 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,075-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 10:52:31,486 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 10:52:31,486-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 10:52:31,658 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 10:52:31,658-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 10:52:31,876 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 10:52:31,876-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 10:52:31,887 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 10:52:31,887-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 14:43:45,254 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 14:43:45,254-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 14:43:45,760 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 14:43:45,760-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 14:43:45,926 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 14:43:45,926-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 14:43:45,945 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 14:43:45,945-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 14:43:45,945 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 14:43:45,945-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 14:43:45,946 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 14:43:45,946-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 14:43:45,947 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 14:43:45,947-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 14:43:45,947 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 14:43:45,947-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 14:43:46,229 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 56580.
2018-12-06 14:43:46,229-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 56580.
2018-12-06 14:43:46,248 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 14:43:46,248-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 14:43:46,263 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 14:43:46,263-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 14:43:46,266 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 14:43:46,266-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 14:43:46,266 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 14:43:46,266-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 14:43:46,274 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e3ca7eb7-abf4-432e-bc28-ddca5926787c
2018-12-06 14:43:46,274-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e3ca7eb7-abf4-432e-bc28-ddca5926787c
2018-12-06 14:43:46,321 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 14:43:46,321-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 14:43:46,373 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 14:43:46,373-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 14:43:46,454 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1967ms
2018-12-06 14:43:46,454-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1967ms
2018-12-06 14:43:46,514 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 14:43:46,514-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 14:43:46,528 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2043ms
2018-12-06 14:43:46,528-[TS] INFO main org.spark_project.jetty.server.Server - Started @2043ms
2018-12-06 14:43:46,545 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@f42722d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 14:43:46,545-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@f42722d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 14:43:46,545 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 14:43:46,545-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 14:43:46,569 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,569-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,570 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,570-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,571 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,571-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,572 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,572-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,573 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,573-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,573 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,573-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,574 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,574-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,576 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,576-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,577 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,577-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,578 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,578-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,580 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,580-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,580 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,580-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,581 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,581-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,582 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,582-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,583 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,583-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,585 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,585-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,586 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,586-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,587 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,587-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,588 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,588-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,589 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,589-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,596 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,596-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,597 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,597-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,598 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,598-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,599 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,599-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,599 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,599-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,601 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 14:43:46,601-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 14:43:46,671 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 14:43:46,671-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 14:43:46,689 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56581.
2018-12-06 14:43:46,689-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56581.
2018-12-06 14:43:46,690 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:56581
2018-12-06 14:43:46,690-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:56581
2018-12-06 14:43:46,691 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 14:43:46,691-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 14:43:46,712 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,712-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,714 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:56581 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,714-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:56581 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,716 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,716-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,717 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,717-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 56581, None)
2018-12-06 14:43:46,882 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:46,882-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,484 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 14:43:48,484-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 14:43:48,485 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 14:43:48,485-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 14:43:48,490 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,490-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,491 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,491-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,492 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,492-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,492 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,492-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,494 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,494-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 14:43:48,922 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 14:43:48,922-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 14:43:49,080 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 14:43:49,080-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 14:43:49,329 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 14:43:49,329-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 14:43:49,340 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 14:43:49,340-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 14:43:53,248 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 2 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 14:43:53,248-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 2 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 14:43:54,806 [Executor task launch worker for task 232] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 0.0 in stage 5.0 (TID 232)
org.apache.spark.SparkException: Failed to execute user defined function(anonfun$calPerAreaTop3$2: (string) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$2.hasNext(WholeStageCodegenExec.scala:414)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.alibaba.fastjson.JSONException: default constructor not found. class top.newforesee.bean.goods.ExtendInfo
	at com.alibaba.fastjson.util.DeserializeBeanInfo.computeSetters(DeserializeBeanInfo.java:159)
	at com.alibaba.fastjson.parser.ParserConfig.createJavaBeanDeserializer(ParserConfig.java:420)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:382)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:303)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:511)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:244)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:220)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:179)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:327)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$.getProductStatusFunction(HotGoodsAnalysisJob.scala:89)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	... 16 more
2018-12-06 14:43:54,806-[TS] ERROR Executor task launch worker for task 232 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 5.0 (TID 232)
org.apache.spark.SparkException: Failed to execute user defined function(anonfun$calPerAreaTop3$2: (string) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$2.hasNext(WholeStageCodegenExec.scala:414)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.alibaba.fastjson.JSONException: default constructor not found. class top.newforesee.bean.goods.ExtendInfo
	at com.alibaba.fastjson.util.DeserializeBeanInfo.computeSetters(DeserializeBeanInfo.java:159)
	at com.alibaba.fastjson.parser.ParserConfig.createJavaBeanDeserializer(ParserConfig.java:420)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:382)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:303)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:511)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:244)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:220)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:179)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:327)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$.getProductStatusFunction(HotGoodsAnalysisJob.scala:89)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	... 16 more
2018-12-06 14:43:54,825 [task-result-getter-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Lost task 0.0 in stage 5.0 (TID 232, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(anonfun$calPerAreaTop3$2: (string) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$2.hasNext(WholeStageCodegenExec.scala:414)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.alibaba.fastjson.JSONException: default constructor not found. class top.newforesee.bean.goods.ExtendInfo
	at com.alibaba.fastjson.util.DeserializeBeanInfo.computeSetters(DeserializeBeanInfo.java:159)
	at com.alibaba.fastjson.parser.ParserConfig.createJavaBeanDeserializer(ParserConfig.java:420)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:382)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:303)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:511)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:244)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:220)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:179)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:327)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$.getProductStatusFunction(HotGoodsAnalysisJob.scala:89)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	... 16 more

2018-12-06 14:43:54,825-[TS] WARN task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 5.0 (TID 232, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function(anonfun$calPerAreaTop3$2: (string) => string)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$2.hasNext(WholeStageCodegenExec.scala:414)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:234)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:228)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.alibaba.fastjson.JSONException: default constructor not found. class top.newforesee.bean.goods.ExtendInfo
	at com.alibaba.fastjson.util.DeserializeBeanInfo.computeSetters(DeserializeBeanInfo.java:159)
	at com.alibaba.fastjson.parser.ParserConfig.createJavaBeanDeserializer(ParserConfig.java:420)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:382)
	at com.alibaba.fastjson.parser.ParserConfig.getDeserializer(ParserConfig.java:303)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:511)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:244)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:220)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:179)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:327)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$.getProductStatusFunction(HotGoodsAnalysisJob.scala:89)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	at top.newforesee.jobs.goods.HotGoodsAnalysisJob$$anonfun$calPerAreaTop3$2.apply(HotGoodsAnalysisJob.scala:55)
	... 16 more

2018-12-06 14:43:54,826 [task-result-getter-2] [org.apache.spark.scheduler.TaskSetManager] [ERROR] - Task 0 in stage 5.0 failed 1 times; aborting job
2018-12-06 14:43:54,826-[TS] ERROR task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 5.0 failed 1 times; aborting job
2018-12-06 14:45:49,315 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 14:45:49,315-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 14:45:49,719 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 14:45:49,719-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 14:45:49,870 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 14:45:49,870-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 14:45:49,892 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 14:45:49,892-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 14:45:49,892 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 14:45:49,892-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 14:45:49,893 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 14:45:49,893-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 14:45:49,894 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 14:45:49,894-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 14:45:49,894 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 14:45:49,894-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 14:45:50,155 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 56754.
2018-12-06 14:45:50,155-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 56754.
2018-12-06 14:45:50,170 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 14:45:50,170-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 14:45:50,184 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 14:45:50,184-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 14:45:50,186 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 14:45:50,186-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 14:45:50,187 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 14:45:50,187-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 14:45:50,194 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6882b215-40b5-4cda-aeba-77fea87b24d7
2018-12-06 14:45:50,194-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6882b215-40b5-4cda-aeba-77fea87b24d7
2018-12-06 14:45:50,237 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 14:45:50,237-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 14:45:50,289 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 14:45:50,289-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 14:45:50,369 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1684ms
2018-12-06 14:45:50,369-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1684ms
2018-12-06 14:45:50,426 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 14:45:50,426-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 14:45:50,442 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1757ms
2018-12-06 14:45:50,442-[TS] INFO main org.spark_project.jetty.server.Server - Started @1757ms
2018-12-06 14:45:50,461 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 14:45:50,461-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 14:45:50,461 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 14:45:50,461-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 14:45:50,485 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,485-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,486 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,486-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,487 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,487-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,489 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,489-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,490 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,490-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,491 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,491-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,493 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,493-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,494 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,494-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,495 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,495-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,496 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,496-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,496 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,496-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,497 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,497-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,499 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,499-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,500 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,500-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,501 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,501-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,502 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,502-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,503 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,503-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,504 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,504-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,505 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,505-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,506 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,506-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,515 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,515-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,516 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,516-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,518 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,518-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,520 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,520-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,520 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,520-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,523 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 14:45:50,523-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 14:45:50,613 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 14:45:50,613-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 14:45:50,634 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56755.
2018-12-06 14:45:50,634-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56755.
2018-12-06 14:45:50,635 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:56755
2018-12-06 14:45:50,635-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:56755
2018-12-06 14:45:50,636 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 14:45:50,636-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 14:45:50,660 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,660-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,664 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:56755 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,664-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:56755 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,666 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,666-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,666 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,666-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 56755, None)
2018-12-06 14:45:50,827 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:50,827-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,301 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 14:45:52,301-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 14:45:52,302 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 14:45:52,302-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 14:45:52,308 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,308-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,309 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,309-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,310 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,310-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,310 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,310-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,312 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,312-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 14:45:52,757 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 14:45:52,757-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 14:45:52,906 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 14:45:52,906-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 14:45:53,133 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 14:45:53,133-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 14:45:53,144 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 14:45:53,144-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 14:45:56,707 [dispatcher-event-loop-0] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 2 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 14:45:56,707-[TS] WARN dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Stage 2 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:38:27,288 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 19:38:27,288-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 19:38:27,909 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:38:27,909-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:38:28,093 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:38:28,093-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:38:28,120 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 19:38:28,120-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 19:38:28,121 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 19:38:28,121-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 19:38:28,122 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 19:38:28,122-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 19:38:28,122 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 19:38:28,122-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 19:38:28,123 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:38:28,123-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:38:28,534 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51590.
2018-12-06 19:38:28,534-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51590.
2018-12-06 19:38:28,557 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 19:38:28,557-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 19:38:28,577 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 19:38:28,577-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 19:38:28,581 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:38:28,581-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:38:28,582 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 19:38:28,582-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 19:38:28,592 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-b78d5fc8-8e6a-45d8-ac31-21d4c404b29e
2018-12-06 19:38:28,592-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-b78d5fc8-8e6a-45d8-ac31-21d4c404b29e
2018-12-06 19:38:28,640 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:38:28,640-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:38:28,697 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 19:38:28,697-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 19:38:28,809 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2514ms
2018-12-06 19:38:28,809-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2514ms
2018-12-06 19:38:28,888 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 19:38:28,888-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 19:38:28,906 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2612ms
2018-12-06 19:38:28,906-[TS] INFO main org.spark_project.jetty.server.Server - Started @2612ms
2018-12-06 19:38:28,932 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2271d0d7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:38:28,932-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2271d0d7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:38:28,932 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:38:28,932-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:38:28,958 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4b6166aa{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,958-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b6166aa{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,958 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,958-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,959 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,959-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,961 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,961-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,962 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,962-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,962 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,962-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,964 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,964-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,966 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,966-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,967 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,967-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,969 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,969-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,970 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,970-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,970 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,970-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,971 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,971-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,973 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,973-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,974 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,974-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,975 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,975-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,976 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,976-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,977 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,977-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,977 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,977-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,978 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,978-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,996 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/static,null,AVAILABLE,@Spark}
2018-12-06 19:38:28,996-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/static,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,001 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,001-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,005 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/api,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,005-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/api,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,007 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,007-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,008 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,008-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59aa20b3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,011 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:38:29,011-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:38:29,153 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 19:38:29,153-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 19:38:29,174 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51591.
2018-12-06 19:38:29,174-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51591.
2018-12-06 19:38:29,175 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51591
2018-12-06 19:38:29,175-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51591
2018-12-06 19:38:29,177 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:38:29,177-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:38:29,205 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,205-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,209 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51591 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,209-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51591 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,212 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,212-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,212 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,212-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51591, None)
2018-12-06 19:38:29,493 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:29,493-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,703 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:38:31,703-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:38:31,704 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:38:31,704-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:38:31,711 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,711-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,712 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64387c17{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,712-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64387c17{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,713 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,713-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,714 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e62ead7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,714-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e62ead7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,716 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@60ed12e8{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:38:31,716-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60ed12e8{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:38:32,426 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 19:38:32,426-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 19:38:32,671 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 19:38:32,671-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 19:38:32,989 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 19:38:32,989-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 19:38:33,003 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 19:38:33,003-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 19:40:16,619 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 19:40:16,619-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 19:40:17,099 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:40:17,099-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:40:17,277 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:40:17,277-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:40:17,304 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 19:40:17,304-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 19:40:17,305 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 19:40:17,305-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 19:40:17,307 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 19:40:17,307-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 19:40:17,308 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 19:40:17,308-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 19:40:17,309 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:40:17,309-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:40:17,600 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51744.
2018-12-06 19:40:17,600-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51744.
2018-12-06 19:40:17,617 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 19:40:17,617-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 19:40:17,631 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 19:40:17,631-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 19:40:17,633 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:40:17,633-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:40:17,633 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 19:40:17,633-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 19:40:17,640 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6eb91dfd-3b28-46ef-9566-bd3ecefadaa7
2018-12-06 19:40:17,640-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6eb91dfd-3b28-46ef-9566-bd3ecefadaa7
2018-12-06 19:40:17,683 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:40:17,683-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:40:17,733 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 19:40:17,733-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 19:40:17,819 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1905ms
2018-12-06 19:40:17,819-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1905ms
2018-12-06 19:40:17,878 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 19:40:17,878-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 19:40:17,891 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1978ms
2018-12-06 19:40:17,891-[TS] INFO main org.spark_project.jetty.server.Server - Started @1978ms
2018-12-06 19:40:17,909 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:40:17,909-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:40:17,909 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:40:17,909-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:40:17,937 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,937-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,938 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,938-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,939 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,939-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,941 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,941-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,942 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,942-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,942 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,942-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,943 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,943-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,945 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,945-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,947 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,947-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,948 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,948-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,949 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,949-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,950 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,950-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,951 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,951-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,952 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,952-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,953 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,953-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,954 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,954-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,956 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,956-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,956 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,956-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,957 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,957-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,958 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,958-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,967 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,967-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,969 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,969-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,970 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,970-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,971 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,971-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,972 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,972-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:40:17,975 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:40:17,975-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:40:18,061 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 19:40:18,061-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 19:40:18,084 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51745.
2018-12-06 19:40:18,084-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51745.
2018-12-06 19:40:18,085 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51745
2018-12-06 19:40:18,085-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51745
2018-12-06 19:40:18,087 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:40:18,087-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:40:18,118 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,118-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,121 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51745 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,121-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51745 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,124 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,124-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,125 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,125-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51745, None)
2018-12-06 19:40:18,336 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:18,336-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,825 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:40:19,825-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:40:19,826 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:40:19,826-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:40:19,834 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,834-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,835 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,835-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,836 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,836-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,837 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,837-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,839 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:40:19,839-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:40:20,243 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 19:40:20,243-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 19:40:20,398 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 19:40:20,398-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 19:40:20,624 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 19:40:20,624-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 19:40:20,636 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 19:40:20,636-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 19:40:25,104 [dispatcher-event-loop-4] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 2 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:40:25,104-[TS] WARN dispatcher-event-loop-4 org.apache.spark.scheduler.TaskSetManager - Stage 2 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:41:22,831 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 19:41:22,831-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 19:41:23,256 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:41:23,256-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:41:23,411 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:41:23,411-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:41:23,431 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 19:41:23,431-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 19:41:23,432 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 19:41:23,432-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 19:41:23,432 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 19:41:23,432-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 19:41:23,433 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 19:41:23,433-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 19:41:23,434 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:41:23,434-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:41:23,714 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51856.
2018-12-06 19:41:23,714-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51856.
2018-12-06 19:41:23,728 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 19:41:23,728-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 19:41:23,743 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 19:41:23,743-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 19:41:23,745 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:41:23,745-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:41:23,745 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 19:41:23,745-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 19:41:23,752 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-47197374-9f5d-4b9a-b3d6-c2f1f3bd1cf6
2018-12-06 19:41:23,752-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-47197374-9f5d-4b9a-b3d6-c2f1f3bd1cf6
2018-12-06 19:41:23,795 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:41:23,795-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:41:23,845 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 19:41:23,845-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 19:41:23,934 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1829ms
2018-12-06 19:41:23,934-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1829ms
2018-12-06 19:41:23,993 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 19:41:23,993-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 19:41:24,008 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1904ms
2018-12-06 19:41:24,008-[TS] INFO main org.spark_project.jetty.server.Server - Started @1904ms
2018-12-06 19:41:24,024 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:41:24,024-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:41:24,024 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:41:24,024-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:41:24,049 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,049-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,050 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,050-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,054 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,054-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,055 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,055-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,056 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,056-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,056 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,056-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,057 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,057-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,059 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,059-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,060 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,060-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,061 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,061-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,062 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,062-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,063 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,063-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,064 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,064-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,065 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,065-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,066 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,066-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,067 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,067-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,068 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,068-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,069 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,069-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,070 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,070-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,072 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,072-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,086 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,086-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,087 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,087-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,089 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,089-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,090 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,090-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,091 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,091-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,093 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:41:24,093-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:41:24,209 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 19:41:24,209-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 19:41:24,230 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51857.
2018-12-06 19:41:24,230-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51857.
2018-12-06 19:41:24,231 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51857
2018-12-06 19:41:24,231-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51857
2018-12-06 19:41:24,233 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:41:24,233-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:41:24,256 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,256-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,258 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51857 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,258-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51857 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,260 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,260-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,260 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,260-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51857, None)
2018-12-06 19:41:24,415 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:24,415-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,848 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:41:25,848-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:41:25,848 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:41:25,848-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:41:25,854 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,854-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,854 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,854-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,855 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,855-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,855 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,855-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,856 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:41:25,856-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:41:26,232 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 19:41:26,232-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 19:41:26,369 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 19:41:26,369-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 19:41:26,601 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 19:41:26,601-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 19:41:26,615 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 19:41:26,615-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 19:41:30,249 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 3 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:41:30,249-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 3 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:42:45,661 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 19:42:45,661-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 19:42:46,084 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:42:46,084-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 19:42:46,258 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:42:46,258-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 19:42:46,280 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 19:42:46,280-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 19:42:46,281 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 19:42:46,281-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 19:42:46,281 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 19:42:46,281-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 19:42:46,282 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 19:42:46,282-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 19:42:46,283 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:42:46,283-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 19:42:46,566 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 51979.
2018-12-06 19:42:46,566-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51979.
2018-12-06 19:42:46,583 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 19:42:46,583-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 19:42:46,598 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 19:42:46,598-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 19:42:46,601 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:42:46,601-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 19:42:46,601 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 19:42:46,601-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 19:42:46,608 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-40524348-4a13-4b80-a4fb-105befb600f9
2018-12-06 19:42:46,608-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-40524348-4a13-4b80-a4fb-105befb600f9
2018-12-06 19:42:46,657 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:42:46,657-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 19:42:46,712 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 19:42:46,712-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 19:42:46,796 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1781ms
2018-12-06 19:42:46,796-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1781ms
2018-12-06 19:42:46,846 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 19:42:46,846-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 19:42:46,862 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1848ms
2018-12-06 19:42:46,862-[TS] INFO main org.spark_project.jetty.server.Server - Started @1848ms
2018-12-06 19:42:46,879 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:42:46,879-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@1fc0053e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 19:42:46,880 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:42:46,880-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 19:42:46,903 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,903-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b91d8c4{/jobs,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,904 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,904-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,905 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,905-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,906 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,906-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,907 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,907-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,908 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,908-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,909 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,909-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,911 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,911-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,913 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,913-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,914 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,914-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,915 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,915-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,916 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,916-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,917 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,917-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,918 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,918-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,919 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,919-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/environment,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,920 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,920-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,921 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,921-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,922 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,922-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,924 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,924-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,925 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,925-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,936 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,936-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/static,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,937 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,937-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,939 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,939-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/api,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,941 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,941-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,942 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,942-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a69561c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 19:42:46,944 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:42:46,944-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 19:42:47,080 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 19:42:47,080-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 19:42:47,106 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51980.
2018-12-06 19:42:47,106-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51980.
2018-12-06 19:42:47,107 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:51980
2018-12-06 19:42:47,107-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:51980
2018-12-06 19:42:47,108 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:42:47,108-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 19:42:47,130 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,130-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,132 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:51980 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,132-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:51980 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,134 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,134-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,134 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,134-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 51980, None)
2018-12-06 19:42:47,294 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:47,294-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cfbaf4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,801 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:42:48,801-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 19:42:48,802 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:42:48,802-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 19:42:48,808 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,808-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,809 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,809-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,809 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,809-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,810 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,810-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,811 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:42:48,811-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 19:42:49,224 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 19:42:49,224-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 19:42:49,383 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 19:42:49,383-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 19:42:49,596 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 19:42:49,596-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 19:42:49,607 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 19:42:49,607-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 19:42:57,727 [dispatcher-event-loop-0] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 2 contains a task of very large size (106 KB). The maximum recommended task size is 100 KB.
2018-12-06 19:42:57,727-[TS] WARN dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Stage 2 contains a task of very large size (106 KB). The maximum recommended task size is 100 KB.
2018-12-06 20:15:05,659 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 20:15:05,659-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 20:15:06,138 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 20:15:06,138-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 20:15:06,327 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: HotGoodsAnalysisJob$
2018-12-06 20:15:06,327-[TS] INFO main org.apache.spark.SparkContext - Submitted application: HotGoodsAnalysisJob$
2018-12-06 20:15:06,353 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 20:15:06,353-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 20:15:06,354 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 20:15:06,354-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 20:15:06,355 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 20:15:06,355-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 20:15:06,355 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 20:15:06,355-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 20:15:06,356 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 20:15:06,356-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 20:15:06,689 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 54529.
2018-12-06 20:15:06,689-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54529.
2018-12-06 20:15:06,708 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 20:15:06,708-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 20:15:06,726 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 20:15:06,726-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 20:15:06,729 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 20:15:06,729-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 20:15:06,730 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 20:15:06,730-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 20:15:06,738 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-62c6f9bd-6d2b-4572-bcde-6dc08531e9cc
2018-12-06 20:15:06,738-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-62c6f9bd-6d2b-4572-bcde-6dc08531e9cc
2018-12-06 20:15:06,792 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 20:15:06,792-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 20:15:06,856 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 20:15:06,856-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 20:15:06,969 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2110ms
2018-12-06 20:15:06,969-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2110ms
2018-12-06 20:15:07,029 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 20:15:07,029-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 20:15:07,042 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2185ms
2018-12-06 20:15:07,042-[TS] INFO main org.spark_project.jetty.server.Server - Started @2185ms
2018-12-06 20:15:07,063 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@1481a339{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 20:15:07,063-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@1481a339{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 20:15:07,064 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 20:15:07,064-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 20:15:07,093 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7807ac2c{/jobs,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,093-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7807ac2c{/jobs,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,094 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,094-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,095 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,095-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,097 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,097-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,098 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/stages,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,098-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/stages,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,099 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,099-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,100 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,100-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,102 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,102-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,103 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,103-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,104 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,104-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,105 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,105-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,107 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,107-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,108 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,108-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,109 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,109-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,109 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/environment,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,109-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/environment,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,110 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,110-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,113 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,113-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,114 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,114-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,115 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,115-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,126 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/static,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,126-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/static,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,128 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@48c40605{/,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,128-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48c40605{/,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,131 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/api,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,131-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/api,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,133 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21ec5d87{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,133-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ec5d87{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,134 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,134-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,137 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 20:15:07,137-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 20:15:07,282 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 20:15:07,282-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 20:15:07,315 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54530.
2018-12-06 20:15:07,315-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54530.
2018-12-06 20:15:07,316 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:54530
2018-12-06 20:15:07,316-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:54530
2018-12-06 20:15:07,319 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 20:15:07,319-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 20:15:07,349 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,349-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,352 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:54530 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,352-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:54530 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,356 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,356-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,356 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,356-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 54530, None)
2018-12-06 20:15:07,546 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a60ee36{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:07,546-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a60ee36{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,403 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 20:15:09,403-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 20:15:09,404 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 20:15:09,404-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 20:15:09,410 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,410-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,411 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,411-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,412 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,412-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,412 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,412-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,414 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,414-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 20:15:09,937 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 20:15:09,937-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 20:15:10,095 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 20:15:10,095-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 20:15:10,360 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 20:15:10,360-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 20:15:10,377 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 20:15:10,377-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 20:15:14,342 [dispatcher-event-loop-6] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 2 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2018-12-06 20:15:14,342-[TS] WARN dispatcher-event-loop-6 org.apache.spark.scheduler.TaskSetManager - Stage 2 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:42:26,798 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:42:26,798-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:42:27,346 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:42:27,346-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:42:27,588 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:42:27,588-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:42:27,617 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:42:27,617-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:42:27,618 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:42:27,618-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:42:27,618 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:42:27,618-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:42:27,619 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:42:27,619-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:42:27,620 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:42:27,620-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:42:27,968 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 61310.
2018-12-06 21:42:27,968-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61310.
2018-12-06 21:42:27,995 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:42:27,995-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:42:28,018 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:42:28,018-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:42:28,023 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:42:28,023-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:42:28,024 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:42:28,024-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:42:28,035 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6305638c-f029-4b67-99bb-4ca07967952a
2018-12-06 21:42:28,035-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6305638c-f029-4b67-99bb-4ca07967952a
2018-12-06 21:42:28,091 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:42:28,091-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:42:28,173 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:42:28,173-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:42:28,331 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2271ms
2018-12-06 21:42:28,331-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2271ms
2018-12-06 21:42:28,456 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:42:28,456-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:42:28,487 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2430ms
2018-12-06 21:42:28,487-[TS] INFO main org.spark_project.jetty.server.Server - Started @2430ms
2018-12-06 21:42:28,529 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@69543d17{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:42:28,529-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@69543d17{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:42:28,530 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:42:28,530-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:42:28,592 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7cbee484{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,592-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cbee484{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,594 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,594-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,594 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,594-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,597 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,597-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,598 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,598-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,599 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,599-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,601 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,601-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,603 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,603-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,605 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,605-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,606 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,606-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,607 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,607-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,608 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,608-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,609 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,609-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,610 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,610-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,611 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,611-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,612 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,612-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,613 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,613-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,614 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,614-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,615 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,615-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,617 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,617-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,629 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/static,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,629-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/static,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,631 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2a2da905{/,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,631-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,632 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@60cf80e7{/api,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,632-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60cf80e7{/api,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,634 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,634-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,635 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,635-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bd7f8dc{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,638 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:42:28,638-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:42:28,737 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:42:28,737-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:42:28,755 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61312.
2018-12-06 21:42:28,755-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61312.
2018-12-06 21:42:28,755 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:61312
2018-12-06 21:42:28,755-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:61312
2018-12-06 21:42:28,757 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:42:28,757-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:42:28,776 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,776-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,779 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:61312 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,779-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:61312 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,781 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,781-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,781 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,781-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61312, None)
2018-12-06 21:42:28,973 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5f5b5ca4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:28,973-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f5b5ca4{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,091 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:42:31,091-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:42:31,091 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:42:31,091-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:42:31,098 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,098-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,098 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64387c17{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,098-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64387c17{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,099 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,099-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,100 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e62ead7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,100-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e62ead7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,101 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@60ed12e8{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,101-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60ed12e8{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:42:31,597 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:42:31,597-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:42:31,776 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:42:31,776-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:42:32,022 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:42:32,022-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:42:32,037 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:42:32,037-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:42:39,039 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:42:39,039-[TS] WARN dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:45:00,328 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:45:00,328-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:45:00,803 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:45:00,803-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:45:00,989 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:45:00,989-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:45:01,012 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:45:01,012-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:45:01,012 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:45:01,012-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:45:01,013 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:45:01,013-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:45:01,013 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:45:01,013-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:45:01,014 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:45:01,014-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:45:01,320 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 61531.
2018-12-06 21:45:01,320-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61531.
2018-12-06 21:45:01,336 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:45:01,336-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:45:01,352 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:45:01,352-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:45:01,355 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:45:01,355-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:45:01,356 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:45:01,356-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:45:01,365 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-8ca76727-adc4-4c4b-9798-86e2b62b24c9
2018-12-06 21:45:01,365-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-8ca76727-adc4-4c4b-9798-86e2b62b24c9
2018-12-06 21:45:01,412 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:45:01,412-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:45:01,465 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:45:01,465-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:45:01,542 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1883ms
2018-12-06 21:45:01,542-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1883ms
2018-12-06 21:45:01,597 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:45:01,597-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:45:01,611 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1953ms
2018-12-06 21:45:01,611-[TS] INFO main org.spark_project.jetty.server.Server - Started @1953ms
2018-12-06 21:45:01,628 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@6e9319f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:45:01,628-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@6e9319f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:45:01,629 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:45:01,629-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:45:01,651 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7f811d00{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,651-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7f811d00{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,652 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,652-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,653 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,653-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,654 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,654-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,656 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,656-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,657 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,657-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,658 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,658-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,660 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,660-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,661 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,661-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,662 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,662-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,663 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,663-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,664 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,664-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,665 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,665-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,666 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,666-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,667 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,667-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,669 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,669-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,670 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,670-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,671 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,671-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,672 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,672-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,673 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,673-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,681 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/static,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,681-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/static,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,682 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24f360b2{/,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,682-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24f360b2{/,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,684 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@302fec27{/api,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,684-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@302fec27{/api,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,685 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,685-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,686 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,686-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f2bf0e2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:45:01,688 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:45:01,688-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:45:01,786 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:45:01,786-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:45:01,816 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61533.
2018-12-06 21:45:01,816-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61533.
2018-12-06 21:45:01,817 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:61533
2018-12-06 21:45:01,817-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:61533
2018-12-06 21:45:01,820 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:45:01,820-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:45:01,849 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,849-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,854 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:61533 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,854-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:61533 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,859 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,859-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,860 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:01,860-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61533, None)
2018-12-06 21:45:02,069 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4ee33af7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:02,069-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4ee33af7{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,823 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:45:03,823-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:45:03,825 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:45:03,825-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:45:03,838 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,838-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,840 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7c369270{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,840-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c369270{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,841 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,841-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,844 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b98b809{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,844-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b98b809{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,848 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24c8d8be{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:45:03,848-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24c8d8be{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:45:04,538 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:45:04,538-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:45:04,729 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:45:04,729-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:45:04,994 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:45:04,994-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:45:05,005 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:45:05,005-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:45:08,027 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:45:08,027-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:46:38,855 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:46:38,855-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:46:39,301 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:46:39,301-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:46:39,478 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:46:39,478-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:46:39,500 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:46:39,500-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:46:39,500 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:46:39,500-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:46:39,500 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:46:39,500-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:46:39,501 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:46:39,501-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:46:39,502 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:46:39,502-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:46:39,790 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 61677.
2018-12-06 21:46:39,790-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61677.
2018-12-06 21:46:39,807 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:46:39,807-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:46:39,823 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:46:39,823-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:46:39,827 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:46:39,827-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:46:39,827 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:46:39,827-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:46:39,835 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-80a1104b-c610-4b49-aa3e-43ed9b4f071e
2018-12-06 21:46:39,835-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-80a1104b-c610-4b49-aa3e-43ed9b4f071e
2018-12-06 21:46:39,883 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:46:39,883-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:46:39,947 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:46:39,947-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:46:40,046 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1890ms
2018-12-06 21:46:40,046-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1890ms
2018-12-06 21:46:40,106 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:46:40,106-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:46:40,119 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @1964ms
2018-12-06 21:46:40,119-[TS] INFO main org.spark_project.jetty.server.Server - Started @1964ms
2018-12-06 21:46:40,138 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:46:40,138-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:46:40,138 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:46:40,138-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:46:40,166 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,166-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,167 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,167-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,168 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,168-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,169 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,169-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,170 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,170-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,170 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,170-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,171 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,171-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,173 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,173-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,174 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,174-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,176 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,176-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,177 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,177-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,179 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,179-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,181 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,181-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,182 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,182-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,184 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,184-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,185 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,185-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,186 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,186-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,187 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,187-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,189 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,189-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,199 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,199-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,200 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,200-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,202 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,202-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,203 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,203-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,204 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,204-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,207 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:46:40,207-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:46:40,316 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:46:40,316-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:46:40,340 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61678.
2018-12-06 21:46:40,340-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61678.
2018-12-06 21:46:40,341 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:61678
2018-12-06 21:46:40,341-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:61678
2018-12-06 21:46:40,343 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:46:40,343-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:46:40,367 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,367-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,370 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:61678 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,370-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:61678 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,373 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,373-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,373 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,373-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61678, None)
2018-12-06 21:46:40,535 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:40,535-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,103 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:46:42,103-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:46:42,104 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:46:42,104-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:46:42,111 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,111-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,113 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,113-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,114 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,114-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,115 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,115-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:46:42,535 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:46:42,535-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:46:42,683 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:46:42,683-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:46:42,952 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:46:42,952-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:46:42,965 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:46:42,965-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:46:45,623 [dispatcher-event-loop-6] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:46:45,623-[TS] WARN dispatcher-event-loop-6 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:49:16,062 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:49:16,062-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:49:16,581 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:49:16,581-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:49:16,771 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:49:16,771-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:49:16,811 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:49:16,811-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:49:16,812 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:49:16,812-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:49:16,814 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:49:16,814-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:49:16,816 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:49:16,816-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:49:16,817 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:49:16,817-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:49:17,131 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 61894.
2018-12-06 21:49:17,131-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61894.
2018-12-06 21:49:17,156 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:49:17,156-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:49:17,178 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:49:17,178-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:49:17,183 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:49:17,183-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:49:17,184 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:49:17,184-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:49:17,197 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-eedcd208-32f4-4393-89b5-ef19c4f6f328
2018-12-06 21:49:17,197-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-eedcd208-32f4-4393-89b5-ef19c4f6f328
2018-12-06 21:49:17,249 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:49:17,249-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:49:17,315 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:49:17,315-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:49:17,420 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2087ms
2018-12-06 21:49:17,420-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2087ms
2018-12-06 21:49:17,486 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:49:17,486-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:49:17,500 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2168ms
2018-12-06 21:49:17,500-[TS] INFO main org.spark_project.jetty.server.Server - Started @2168ms
2018-12-06 21:49:17,519 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2a873e37{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:49:17,519-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2a873e37{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:49:17,519 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:49:17,519-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:49:17,550 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,550-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,551 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,551-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,553 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,553-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,554 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,554-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,555 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,555-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,556 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,556-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,557 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,557-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,559 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,559-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,560 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,560-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,561 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,561-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,562 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,562-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,564 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,564-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,565 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,565-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,566 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,566-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,567 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,567-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,568 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,568-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,569 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,569-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,570 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,570-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,571 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,571-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,573 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,573-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,583 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,583-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,584 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,584-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,586 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,586-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,587 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,587-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,588 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,588-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:49:17,590 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:49:17,590-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:49:17,793 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:49:17,793-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:49:17,814 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61896.
2018-12-06 21:49:17,814-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61896.
2018-12-06 21:49:17,815 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:61896
2018-12-06 21:49:17,815-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:61896
2018-12-06 21:49:17,816 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:49:17,816-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:49:17,839 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,839-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,842 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:61896 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,842-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:61896 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,844 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,844-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,845 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:17,845-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 61896, None)
2018-12-06 21:49:18,017 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:18,017-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,885 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:49:19,885-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:49:19,887 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:49:19,887-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:49:19,900 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,900-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,900 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,900-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,902 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,902-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,902 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,902-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,904 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:49:19,904-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:49:20,379 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:49:20,379-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:49:20,565 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:49:20,565-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:49:20,833 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:49:20,833-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:49:20,860 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:49:20,860-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:49:23,632 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:49:23,632-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (107 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:51:54,777 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:51:54,777-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:51:55,281 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:51:55,281-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:51:55,478 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:51:55,478-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:51:55,499 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:51:55,499-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:51:55,500 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:51:55,500-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:51:55,500 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:51:55,500-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:51:55,501 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:51:55,501-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:51:55,501 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:51:55,501-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:51:55,806 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 62176.
2018-12-06 21:51:55,806-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62176.
2018-12-06 21:51:55,826 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:51:55,826-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:51:55,842 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:51:55,842-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:51:55,845 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:51:55,845-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:51:55,845 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:51:55,845-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:51:55,853 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a8c4bebd-53c1-4e40-bd22-bfe37266955e
2018-12-06 21:51:55,853-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a8c4bebd-53c1-4e40-bd22-bfe37266955e
2018-12-06 21:51:55,897 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:51:55,897-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:51:55,955 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:51:55,955-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:51:56,054 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @1976ms
2018-12-06 21:51:56,054-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @1976ms
2018-12-06 21:51:56,108 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:51:56,108-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:51:56,120 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2043ms
2018-12-06 21:51:56,120-[TS] INFO main org.spark_project.jetty.server.Server - Started @2043ms
2018-12-06 21:51:56,137 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:51:56,137-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2416a51{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:51:56,137 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:51:56,137-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:51:56,161 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,161-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,162 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,162-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,162 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,162-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,164 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,164-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,165 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,165-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,166 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,166-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,167 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,167-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,169 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,169-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,170 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,170-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,171 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,171-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,172 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,172-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,173 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,173-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,173 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,173-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,174 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,174-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,175 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,175-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,176 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,176-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,179 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,179-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,180 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,180-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,200 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,200-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,202 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,202-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,204 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,204-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,205 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,205-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,206 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,206-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,208 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:51:56,208-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:51:56,299 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:51:56,299-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:51:56,328 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62179.
2018-12-06 21:51:56,328-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62179.
2018-12-06 21:51:56,329 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:62179
2018-12-06 21:51:56,329-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:62179
2018-12-06 21:51:56,330 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:51:56,330-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:51:56,354 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,354-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,360 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:62179 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,360-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:62179 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,362 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,362-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,362 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,362-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62179, None)
2018-12-06 21:51:56,540 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:56,540-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,213 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:51:58,213-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:51:58,214 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:51:58,214-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:51:58,223 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,223-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,224 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,224-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,225 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,225-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,226 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,226-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,228 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,228-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:51:58,729 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:51:58,729-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:51:58,871 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:51:58,871-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:51:59,100 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:51:59,100-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:51:59,112 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:51:59,112-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:52:02,612 [dispatcher-event-loop-6] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:52:02,612-[TS] WARN dispatcher-event-loop-6 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:53:57,376 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:53:57,376-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:53:57,964 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:53:57,964-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:53:58,210 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:53:58,210-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:53:58,260 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:53:58,260-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:53:58,261 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:53:58,261-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:53:58,261 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:53:58,261-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:53:58,262 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:53:58,262-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:53:58,263 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:53:58,263-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:53:58,544 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 62353.
2018-12-06 21:53:58,544-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62353.
2018-12-06 21:53:58,560 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:53:58,560-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:53:58,573 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:53:58,573-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:53:58,576 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:53:58,576-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:53:58,576 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:53:58,576-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:53:58,584 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-ddb75431-7458-4ed9-9ff7-7c7466701e83
2018-12-06 21:53:58,584-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-ddb75431-7458-4ed9-9ff7-7c7466701e83
2018-12-06 21:53:58,636 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:53:58,636-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:53:58,687 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:53:58,687-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:53:58,776 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2139ms
2018-12-06 21:53:58,776-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2139ms
2018-12-06 21:53:58,831 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:53:58,831-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:53:58,844 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2208ms
2018-12-06 21:53:58,844-[TS] INFO main org.spark_project.jetty.server.Server - Started @2208ms
2018-12-06 21:53:58,864 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@24e18c6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:53:58,864-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@24e18c6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:53:58,864 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:53:58,864-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:53:58,891 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,891-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bb3a9fe{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,892 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,892-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,893 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,893-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,894 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,894-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,895 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,895-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,896 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,896-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,897 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,897-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66ea1466{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,899 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,899-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,900 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,900-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,901 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,901-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,902 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,902-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,903 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,903-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,904 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,904-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,905 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,905-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,906 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,906-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,908 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,908-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,909 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,909-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,910 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,910-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,911 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,911-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,912 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,912-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,919 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,919-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/static,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,920 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,920-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,922 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,922-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24f360b2{/api,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,924 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,924-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,925 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,925-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6cea706c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:53:58,927 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:53:58,927-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:53:59,016 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:53:59,016-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:53:59,037 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62354.
2018-12-06 21:53:59,037-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62354.
2018-12-06 21:53:59,038 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:62354
2018-12-06 21:53:59,038-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:62354
2018-12-06 21:53:59,039 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:53:59,039-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:53:59,065 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,065-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,068 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:62354 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,068-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:62354 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,070 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,070-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,071 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,071-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62354, None)
2018-12-06 21:53:59,284 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:53:59,284-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e6ba49a{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,745 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:54:00,745-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:54:00,745 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:54:00,745-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:54:00,751 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,751-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,751 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,751-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,752 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,752-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,753 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,753-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,754 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:54:00,754-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:54:01,151 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:54:01,151-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:54:01,311 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:54:01,311-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:54:01,527 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:54:01,527-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:54:01,539 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:54:01,539-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:54:04,299 [dispatcher-event-loop-6] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:54:04,299-[TS] WARN dispatcher-event-loop-6 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (105 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:57:28,293 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-12-06 21:57:28,293-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-12-06 21:57:28,798 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:57:28,798-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-06 21:57:29,024 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: PageConvertRateJob$
2018-12-06 21:57:29,024-[TS] INFO main org.apache.spark.SparkContext - Submitted application: PageConvertRateJob$
2018-12-06 21:57:29,046 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-12-06 21:57:29,046-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-12-06 21:57:29,047 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-12-06 21:57:29,047-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-12-06 21:57:29,047 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-12-06 21:57:29,047-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-12-06 21:57:29,048 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-12-06 21:57:29,048-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-12-06 21:57:29,049 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:57:29,049-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-12-06 21:57:29,417 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 62638.
2018-12-06 21:57:29,417-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62638.
2018-12-06 21:57:29,436 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-12-06 21:57:29,436-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-12-06 21:57:29,453 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-12-06 21:57:29,453-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-12-06 21:57:29,455 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:57:29,455-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-06 21:57:29,456 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-12-06 21:57:29,456-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-12-06 21:57:29,463 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-76d279c2-7b99-4f79-bb77-75cb8c94f07d
2018-12-06 21:57:29,463-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-76d279c2-7b99-4f79-bb77-75cb8c94f07d
2018-12-06 21:57:29,520 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:57:29,520-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-12-06 21:57:29,591 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-12-06 21:57:29,591-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-12-06 21:57:29,705 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @2461ms
2018-12-06 21:57:29,705-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @2461ms
2018-12-06 21:57:29,768 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-12-06 21:57:29,768-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-12-06 21:57:29,780 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @2537ms
2018-12-06 21:57:29,780-[TS] INFO main org.spark_project.jetty.server.Server - Started @2537ms
2018-12-06 21:57:29,796 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@42d40937{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:57:29,796-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@42d40937{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-06 21:57:29,796 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:57:29,796-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-12-06 21:57:29,823 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,823-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@611f8234{/jobs,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,825 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,825-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,825 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,825-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7de0c6ae{/jobs/job,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,827 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,827-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,828 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,828-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,829 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,829-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,830 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,830-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5471388b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,833 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,833-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,835 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,835-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,836 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,836-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,837 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,837-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,838 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,838-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,840 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,840-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,841 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,841-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,842 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,842-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,843 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,843-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/environment/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,844 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,844-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,845 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,845-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,846 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,846-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,847 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,847-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,856 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,856-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/static,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,857 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,857-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,858 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,858-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a2da905{/api,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,859 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,859-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,860 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,860-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@476aac9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-06 21:57:29,862 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:57:29,862-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.155.224:4040
2018-12-06 21:57:29,949 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-12-06 21:57:29,949-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-12-06 21:57:29,970 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62640.
2018-12-06 21:57:29,970-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62640.
2018-12-06 21:57:29,971 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 10.0.155.224:62640
2018-12-06 21:57:29,971-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.155.224:62640
2018-12-06 21:57:29,972 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:57:29,972-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-06 21:57:29,993 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,993-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,995 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 10.0.155.224:62640 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,995-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.155.224:62640 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,998 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,998-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,999 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:29,999-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.155.224, 62640, None)
2018-12-06 21:57:30,146 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:30,146-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62a8fd44{/metrics/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,641 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:57:31,641-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-12-06 21:57:31,641 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:57:31,641-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-12-06 21:57:31,648 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,648-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,649 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,649-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,650 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,650-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,651 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,651-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,653 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:57:31,653-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-12-06 21:57:32,058 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-12-06 21:57:32,058-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-12-06 21:57:32,201 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-12-06 21:57:32,201-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-12-06 21:57:32,437 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-12-06 21:57:32,437-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-12-06 21:57:32,452 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-12-06 21:57:32,452-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-12-06 21:57:39,497 [dispatcher-event-loop-2] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2018-12-06 21:57:39,497-[TS] WARN dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (109 KB). The maximum recommended task size is 100 KB.
2019-04-07 23:30:54,837 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2019-04-07 23:30:54,837-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2019-04-07 23:30:57,513 [main] [org.apache.hadoop.util.Shell] [ERROR] - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:8)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:30:57,513-[TS] ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:8)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:30:57,936 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:30:57,936-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:30:59,829 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: SparkWC
2019-04-07 23:30:59,829-[TS] INFO main org.apache.spark.SparkContext - Submitted application: SparkWC
2019-04-07 23:30:59,938 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newfo
2019-04-07 23:30:59,938-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newfo
2019-04-07 23:30:59,938 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newfo
2019-04-07 23:30:59,938-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newfo
2019-04-07 23:30:59,938 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2019-04-07 23:30:59,938-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2019-04-07 23:30:59,954 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2019-04-07 23:30:59,954-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2019-04-07 23:30:59,954 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:30:59,954-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:31:03,118 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 49656.
2019-04-07 23:31:03,118-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 49656.
2019-04-07 23:31:03,243 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2019-04-07 23:31:03,243-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2019-04-07 23:31:03,321 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2019-04-07 23:31:03,321-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2019-04-07 23:31:03,352 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:31:03,352-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:31:03,352 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2019-04-07 23:31:03,352-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2019-04-07 23:31:03,399 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-7ed79b4a-9161-4805-9921-36ed1a31b1ff
2019-04-07 23:31:03,399-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-7ed79b4a-9161-4805-9921-36ed1a31b1ff
2019-04-07 23:31:03,659 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 888.9 MB
2019-04-07 23:31:03,659-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 888.9 MB
2019-04-07 23:31:03,956 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2019-04-07 23:31:03,956-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2019-04-07 23:31:04,456 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @16235ms
2019-04-07 23:31:04,456-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @16235ms
2019-04-07 23:31:04,753 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2019-04-07 23:31:04,753-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2019-04-07 23:31:04,815 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @16595ms
2019-04-07 23:31:04,815-[TS] INFO main org.spark_project.jetty.server.Server - Started @16595ms
2019-04-07 23:31:04,909 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@47da3952{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:31:04,909-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@47da3952{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:31:04,909 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:31:04,909-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:31:05,050 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fff253c{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,050-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fff253c{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,050 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3a1d593e{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,050-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1d593e{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,065 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@361c294e{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,065-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@361c294e{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@314b8f2d{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b8f2d{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5118388b{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5118388b{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7876d598{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,081-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7876d598{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5af28b27{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5af28b27{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@549621f3{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,097-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@549621f3{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32232e55{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32232e55{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37ebc9d8{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2416a51{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2416a51{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6e9319f{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,112-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6e9319f{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,128 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bf9b098{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,128-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bf9b098{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,128 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@77307458{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,128-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77307458{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,144 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@290b1b2e{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,144-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@290b1b2e{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,144 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@33617539{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,144-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33617539{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,159 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5db4c359{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,159-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5db4c359{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,175 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@18e7143f{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,175-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18e7143f{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,175 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@74cec793{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,175-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74cec793{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,218 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4f8969b0{/static,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,218-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f8969b0{/static,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,218 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1922e6d{/,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,218-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1922e6d{/,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6bab2585{/api,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bab2585{/api,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7cbee484{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cbee484{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,234-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62923ee6{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:31:05,250 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:31:05,250-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:31:05,860 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2019-04-07 23:31:05,860-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2019-04-07 23:31:05,954 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49671.
2019-04-07 23:31:05,954-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49671.
2019-04-07 23:31:05,970 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.113:49671
2019-04-07 23:31:05,970-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.113:49671
2019-04-07 23:31:05,970 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:31:05,970-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:31:06,079 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,079-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,095 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.113:49671 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,095-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.113:49671 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,126 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,126-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,126 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:06,126-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 49671, None)
2019-04-07 23:31:07,047 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@27494e46{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,047-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27494e46{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,538 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:31:07,538-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:31:07,554 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:31:07,554-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:31:07,569 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@389562d6{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,569-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@389562d6{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2160e52a{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2160e52a{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6b410923{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6b410923{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@203dd56b{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,585-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@203dd56b{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,600 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26a94fa5{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:31:07,600-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26a94fa5{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:31:11,248 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2019-04-07 23:31:11,248-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2019-04-07 23:31:15,284 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Pruning directories with: 
2019-04-07 23:31:15,284-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pruning directories with: 
2019-04-07 23:31:15,299 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Post-Scan Filters: 
2019-04-07 23:31:15,299-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: 
2019-04-07 23:31:15,299 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Output Data Schema: struct<value: string>
2019-04-07 23:31:15,299-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<value: string>
2019-04-07 23:31:15,315 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Pushed Filters: 
2019-04-07 23:31:15,315-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Pushed Filters: 
2019-04-07 23:31:16,440 [main] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 680.4377 ms
2019-04-07 23:31:16,440-[TS] INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 680.4377 ms
2019-04-07 23:31:16,518 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:31:16,518-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:31:16,643 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:31:16,643-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:31:16,643 [dispatcher-event-loop-1] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_0_piece0 in memory on 192.168.0.113:49671 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:31:16,643-[TS] INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.0.113:49671 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:31:16,659 [main] [org.apache.spark.SparkContext] [INFO] - Created broadcast 0 from rdd at WordCount.scala:10
2019-04-07 23:31:16,659-[TS] INFO main org.apache.spark.SparkContext - Created broadcast 0 from rdd at WordCount.scala:10
2019-04-07 23:31:16,674 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:31:16,674-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:31:17,027 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Invoking stop() from shutdown hook
2019-04-07 23:31:17,027-[TS] INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2019-04-07 23:31:17,043 [Thread-2] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Stopped Spark@47da3952{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:31:17,043-[TS] INFO Thread-2 org.spark_project.jetty.server.AbstractConnector - Stopped Spark@47da3952{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:31:17,043 [Thread-2] [org.apache.spark.ui.SparkUI] [INFO] - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:31:17,043-[TS] INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:31:17,059 [dispatcher-event-loop-0] [org.apache.spark.MapOutputTrackerMasterEndpoint] [INFO] - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:31:17,059-[TS] INFO dispatcher-event-loop-0 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:31:17,059 [Thread-2] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore cleared
2019-04-07 23:31:17,059-[TS] INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2019-04-07 23:31:17,074 [Thread-2] [org.apache.spark.storage.BlockManager] [INFO] - BlockManager stopped
2019-04-07 23:31:17,074-[TS] INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
2019-04-07 23:31:17,074 [Thread-2] [org.apache.spark.storage.BlockManagerMaster] [INFO] - BlockManagerMaster stopped
2019-04-07 23:31:17,074-[TS] INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2019-04-07 23:31:17,074 [dispatcher-event-loop-0] [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] [INFO] - OutputCommitCoordinator stopped!
2019-04-07 23:31:17,074-[TS] INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2019-04-07 23:31:17,090 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Successfully stopped SparkContext
2019-04-07 23:31:17,090-[TS] INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
2019-04-07 23:31:17,090 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Shutdown hook called
2019-04-07 23:31:17,090-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2019-04-07 23:31:17,090 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-451db750-f4ae-4a40-9c5a-3b5417943a00
2019-04-07 23:31:17,090-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-451db750-f4ae-4a40-9c5a-3b5417943a00
2019-04-07 23:34:01,019 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2019-04-07 23:34:01,019-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2019-04-07 23:34:01,713 [main] [org.apache.hadoop.util.Shell] [ERROR] - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:8)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:34:01,713-[TS] ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:8)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:34:01,775 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:34:01,775-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:34:02,426 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: SparkWC
2019-04-07 23:34:02,426-[TS] INFO main org.apache.spark.SparkContext - Submitted application: SparkWC
2019-04-07 23:34:02,457 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newfo
2019-04-07 23:34:02,457-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newfo
2019-04-07 23:34:02,457 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newfo
2019-04-07 23:34:02,457-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newfo
2019-04-07 23:34:02,457 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2019-04-07 23:34:02,457-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2019-04-07 23:34:02,457 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2019-04-07 23:34:02,457-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2019-04-07 23:34:02,457 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:34:02,457-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:34:03,207 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 49920.
2019-04-07 23:34:03,207-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 49920.
2019-04-07 23:34:03,238 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2019-04-07 23:34:03,238-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2019-04-07 23:34:03,254 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2019-04-07 23:34:03,254-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2019-04-07 23:34:03,270 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:34:03,270-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:34:03,270 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2019-04-07 23:34:03,270-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2019-04-07 23:34:03,270 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-b5c8adeb-a9a8-4e51-96d2-570f2132d16d
2019-04-07 23:34:03,270-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-b5c8adeb-a9a8-4e51-96d2-570f2132d16d
2019-04-07 23:34:03,332 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 888.9 MB
2019-04-07 23:34:03,332-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 888.9 MB
2019-04-07 23:34:03,410 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2019-04-07 23:34:03,410-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2019-04-07 23:34:03,520 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @10511ms
2019-04-07 23:34:03,520-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @10511ms
2019-04-07 23:34:03,598 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2019-04-07 23:34:03,598-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2019-04-07 23:34:03,613 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @10597ms
2019-04-07 23:34:03,613-[TS] INFO main org.spark_project.jetty.server.Server - Started @10597ms
2019-04-07 23:34:03,629 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@4bbe4885{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:34:03,629-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@4bbe4885{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:34:03,629 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:34:03,629-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:34:03,660 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@591e58fa{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,660-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@591e58fa{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,660 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@361c294e{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,660-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@361c294e{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,660 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@285d851a{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,660-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@285d851a{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5118388b{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5118388b{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7876d598{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7876d598{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5af28b27{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5af28b27{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@549621f3{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@549621f3{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32232e55{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32232e55{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37ebc9d8{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2416a51{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2416a51{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6e9319f{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6e9319f{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bf9b098{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bf9b098{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@77307458{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77307458{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@290b1b2e{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,676-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@290b1b2e{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,692 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@33617539{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,692-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33617539{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5db4c359{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5db4c359{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@18e7143f{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18e7143f{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@74cec793{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74cec793{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4f8969b0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f8969b0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@192f2f27{/static,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@192f2f27{/static,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6bab2585{/,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bab2585{/,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@644c78d4{/api,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/api,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62923ee6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62923ee6{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:34:03,723 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:34:03,723-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:34:03,918 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2019-04-07 23:34:03,918-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2019-04-07 23:34:03,949 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49929.
2019-04-07 23:34:03,949-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49929.
2019-04-07 23:34:03,949 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.113:49929
2019-04-07 23:34:03,949-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.113:49929
2019-04-07 23:34:03,965 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:34:03,965-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:34:03,996 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:03,996-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:03,996 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.113:49929 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:03,996-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.113:49929 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:04,012 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:04,012-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:04,012 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:04,012-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 49929, None)
2019-04-07 23:34:04,231 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1e411d81{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,231-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1e411d81{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,366 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:34:04,366-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:34:04,366 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:34:04,366-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:34:04,366 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3a60c416{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,366-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a60c416{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@469d003c{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@469d003c{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6d64b553{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d64b553{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1d3e6d34{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d3e6d34{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@577f9109{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:34:04,382-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@577f9109{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:34:07,722 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2019-04-07 23:34:07,722-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2019-04-07 23:34:15,558 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Pruning directories with: 
2019-04-07 23:34:15,558-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pruning directories with: 
2019-04-07 23:34:15,558 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Post-Scan Filters: 
2019-04-07 23:34:15,558-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: 
2019-04-07 23:34:15,558 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Output Data Schema: struct<value: string>
2019-04-07 23:34:15,558-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<value: string>
2019-04-07 23:34:15,573 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Pushed Filters: 
2019-04-07 23:34:15,573-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Pushed Filters: 
2019-04-07 23:34:16,604 [main] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 649.958 ms
2019-04-07 23:34:16,604-[TS] INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 649.958 ms
2019-04-07 23:34:16,667 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:34:16,667-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:34:16,776 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:34:16,776-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:34:16,776 [dispatcher-event-loop-0] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_0_piece0 in memory on 192.168.0.113:49929 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:34:16,776-[TS] INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.0.113:49929 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:34:16,792 [main] [org.apache.spark.SparkContext] [INFO] - Created broadcast 0 from rdd at WordCount.scala:10
2019-04-07 23:34:16,792-[TS] INFO main org.apache.spark.SparkContext - Created broadcast 0 from rdd at WordCount.scala:10
2019-04-07 23:34:16,792 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:34:16,792-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:34:17,189 [main] [org.apache.spark.SparkContext] [INFO] - Starting job: foreach at WordCount.scala:14
2019-04-07 23:34:17,189-[TS] INFO main org.apache.spark.SparkContext - Starting job: foreach at WordCount.scala:14
2019-04-07 23:34:17,376 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Registering RDD 5 (map at WordCount.scala:11)
2019-04-07 23:34:17,376-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at WordCount.scala:11)
2019-04-07 23:34:17,392 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Registering RDD 7 (sortBy at WordCount.scala:13)
2019-04-07 23:34:17,392-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (sortBy at WordCount.scala:13)
2019-04-07 23:34:17,392 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Got job 0 (foreach at WordCount.scala:14) with 1 output partitions
2019-04-07 23:34:17,392-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at WordCount.scala:14) with 1 output partitions
2019-04-07 23:34:17,392 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Final stage: ResultStage 2 (foreach at WordCount.scala:14)
2019-04-07 23:34:17,392-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (foreach at WordCount.scala:14)
2019-04-07 23:34:17,392 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Parents of final stage: List(ShuffleMapStage 1)
2019-04-07 23:34:17,392-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2019-04-07 23:34:17,407 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Missing parents: List(ShuffleMapStage 1)
2019-04-07 23:34:17,407-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2019-04-07 23:34:17,407 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:11), which has no missing parents
2019-04-07 23:34:17,407-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:11), which has no missing parents
2019-04-07 23:34:17,532 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_1 stored as values in memory (estimated size 11.4 KB, free 888.6 MB)
2019-04-07 23:34:17,532-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 11.4 KB, free 888.6 MB)
2019-04-07 23:34:17,548 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KB, free 888.6 MB)
2019-04-07 23:34:17,548-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KB, free 888.6 MB)
2019-04-07 23:34:17,548 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_1_piece0 in memory on 192.168.0.113:49929 (size: 6.0 KB, free: 888.9 MB)
2019-04-07 23:34:17,548-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 192.168.0.113:49929 (size: 6.0 KB, free: 888.9 MB)
2019-04-07 23:34:17,548 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 1 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:17,548-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:17,564 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:11) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:17,564-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:11) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:17,564 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 0.0 with 1 tasks
2019-04-07 23:34:17,564-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2019-04-07 23:34:17,610 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2019-04-07 23:34:17,610-[TS] INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2019-04-07 23:34:17,626 [Executor task launch worker for task 0] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 0.0 (TID 0)
2019-04-07 23:34:17,626-[TS] INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2019-04-07 23:34:17,798 [Executor task launch worker for task 0] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 24.9403 ms
2019-04-07 23:34:17,798-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.9403 ms
2019-04-07 23:34:17,845 [Executor task launch worker for task 0] [org.apache.spark.sql.execution.datasources.FileScanRDD] [INFO] - Reading File path: file:///D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/src/main/resources/wc.txt, range: 0-1470, partition values: [empty row]
2019-04-07 23:34:17,845-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/src/main/resources/wc.txt, range: 0-1470, partition values: [empty row]
2019-04-07 23:34:17,887 [Executor task launch worker for task 0] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 19.1927 ms
2019-04-07 23:34:17,887-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.1927 ms
2019-04-07 23:34:18,059 [Executor task launch worker for task 0] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 0.0 (TID 0). 1754 bytes result sent to driver
2019-04-07 23:34:18,059-[TS] INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1754 bytes result sent to driver
2019-04-07 23:34:18,090 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 0.0 (TID 0) in 479 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,090-[TS] INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 479 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,090 [task-result-getter-0] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,090-[TS] INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ShuffleMapStage 0 (map at WordCount.scala:11) finished in 0.511 s
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at WordCount.scala:11) finished in 0.511 s
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - looking for newly runnable stages
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - running: Set()
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - failed: Set()
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
2019-04-07 23:34:18,106 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:13), which has no missing parents
2019-04-07 23:34:18,106-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:13), which has no missing parents
2019-04-07 23:34:18,137 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 888.6 MB)
2019-04-07 23:34:18,137-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 888.6 MB)
2019-04-07 23:34:18,137 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 888.6 MB)
2019-04-07 23:34:18,137-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 888.6 MB)
2019-04-07 23:34:18,137 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_2_piece0 in memory on 192.168.0.113:49929 (size: 2.4 KB, free: 888.9 MB)
2019-04-07 23:34:18,137-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on 192.168.0.113:49929 (size: 2.4 KB, free: 888.9 MB)
2019-04-07 23:34:18,137 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 2 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:18,137-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:18,152 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:13) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:18,152-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:13) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:18,152 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 1.0 with 1 tasks
2019-04-07 23:34:18,152-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2019-04-07 23:34:18,152 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 4610 bytes)
2019-04-07 23:34:18,152-[TS] INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 4610 bytes)
2019-04-07 23:34:18,152 [Executor task launch worker for task 1] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 1.0 (TID 1)
2019-04-07 23:34:18,152-[TS] INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2019-04-07 23:34:18,184 [Executor task launch worker for task 1] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:34:18,184-[TS] INFO Executor task launch worker for task 1 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:34:18,184 [Executor task launch worker for task 1] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Started 0 remote fetches in 0 ms
2019-04-07 23:34:18,184-[TS] INFO Executor task launch worker for task 1 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2019-04-07 23:34:18,309 [Executor task launch worker for task 1] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 1.0 (TID 1). 1283 bytes result sent to driver
2019-04-07 23:34:18,309-[TS] INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1283 bytes result sent to driver
2019-04-07 23:34:18,309 [task-result-getter-1] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 1.0 (TID 1) in 157 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,309-[TS] INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 157 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,309 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ShuffleMapStage 1 (sortBy at WordCount.scala:13) finished in 0.157 s
2019-04-07 23:34:18,309-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (sortBy at WordCount.scala:13) finished in 0.157 s
2019-04-07 23:34:18,309 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - looking for newly runnable stages
2019-04-07 23:34:18,309-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2019-04-07 23:34:18,324 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - running: Set()
2019-04-07 23:34:18,324-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
2019-04-07 23:34:18,324 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - waiting: Set(ResultStage 2)
2019-04-07 23:34:18,324-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2019-04-07 23:34:18,324 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - failed: Set()
2019-04-07 23:34:18,324-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
2019-04-07 23:34:18,324 [task-result-getter-1] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,324-[TS] INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,324 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:13), which has no missing parents
2019-04-07 23:34:18,324-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:13), which has no missing parents
2019-04-07 23:34:18,340 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 888.6 MB)
2019-04-07 23:34:18,340-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 888.6 MB)
2019-04-07 23:34:18,340 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2031.0 B, free 888.6 MB)
2019-04-07 23:34:18,340-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2031.0 B, free 888.6 MB)
2019-04-07 23:34:18,340 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_3_piece0 in memory on 192.168.0.113:49929 (size: 2031.0 B, free: 888.9 MB)
2019-04-07 23:34:18,340-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on 192.168.0.113:49929 (size: 2031.0 B, free: 888.9 MB)
2019-04-07 23:34:18,340 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 3 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:18,340-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:34:18,356 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:13) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:18,356-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:13) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:34:18,356 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 2.0 with 1 tasks
2019-04-07 23:34:18,356-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2019-04-07 23:34:18,356 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:34:18,356-[TS] INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:34:18,356 [Executor task launch worker for task 2] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 2.0 (TID 2)
2019-04-07 23:34:18,356-[TS] INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2019-04-07 23:34:18,371 [Executor task launch worker for task 2] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:34:18,371-[TS] INFO Executor task launch worker for task 2 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:34:18,371 [Executor task launch worker for task 2] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Started 0 remote fetches in 0 ms
2019-04-07 23:34:18,371-[TS] INFO Executor task launch worker for task 2 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2019-04-07 23:34:18,465 [Executor task launch worker for task 2] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 2.0 (TID 2). 1009 bytes result sent to driver
2019-04-07 23:34:18,465-[TS] INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1009 bytes result sent to driver
2019-04-07 23:34:18,465 [task-result-getter-2] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 2.0 (TID 2) in 109 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,465-[TS] INFO task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 109 ms on localhost (executor driver) (1/1)
2019-04-07 23:34:18,465 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ResultStage 2 (foreach at WordCount.scala:14) finished in 0.109 s
2019-04-07 23:34:18,465-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (foreach at WordCount.scala:14) finished in 0.109 s
2019-04-07 23:34:18,465 [task-result-getter-2] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,465-[TS] INFO task-result-getter-2 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-04-07 23:34:18,481 [main] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Job 0 finished: foreach at WordCount.scala:14, took 1.298406 s
2019-04-07 23:34:18,481-[TS] INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at WordCount.scala:14, took 1.298406 s
2019-04-07 23:34:18,496 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Invoking stop() from shutdown hook
2019-04-07 23:34:18,496-[TS] INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2019-04-07 23:34:18,496 [Thread-2] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Stopped Spark@4bbe4885{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:34:18,496-[TS] INFO Thread-2 org.spark_project.jetty.server.AbstractConnector - Stopped Spark@4bbe4885{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:34:18,512 [Thread-2] [org.apache.spark.ui.SparkUI] [INFO] - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:34:18,512-[TS] INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:34:18,527 [dispatcher-event-loop-1] [org.apache.spark.MapOutputTrackerMasterEndpoint] [INFO] - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:34:18,527-[TS] INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:34:18,570 [Thread-2] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore cleared
2019-04-07 23:34:18,570-[TS] INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2019-04-07 23:34:18,570 [Thread-2] [org.apache.spark.storage.BlockManager] [INFO] - BlockManager stopped
2019-04-07 23:34:18,570-[TS] INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
2019-04-07 23:34:18,570 [Thread-2] [org.apache.spark.storage.BlockManagerMaster] [INFO] - BlockManagerMaster stopped
2019-04-07 23:34:18,570-[TS] INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2019-04-07 23:34:18,570 [dispatcher-event-loop-0] [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] [INFO] - OutputCommitCoordinator stopped!
2019-04-07 23:34:18,570-[TS] INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2019-04-07 23:34:18,585 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Successfully stopped SparkContext
2019-04-07 23:34:18,585-[TS] INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
2019-04-07 23:34:18,585 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Shutdown hook called
2019-04-07 23:34:18,585-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2019-04-07 23:34:18,585 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-01bd0271-2866-431c-b0fc-79cf20393c2b
2019-04-07 23:34:18,585-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-01bd0271-2866-431c-b0fc-79cf20393c2b
2019-04-07 23:56:38,990 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2019-04-07 23:56:38,990-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2019-04-07 23:56:40,895 [main] [org.apache.hadoop.util.Shell] [ERROR] - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:9)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:56:40,895-[TS] ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:272)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:790)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:760)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:633)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2427)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2427)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:295)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2516)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:918)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:910)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:910)
	at top.newforesee.jobs.WordCount$.main(WordCount.scala:9)
	at top.newforesee.jobs.WordCount.main(WordCount.scala)
2019-04-07 23:56:40,951 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:56:40,951-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-07 23:56:41,620 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: SparkWC
2019-04-07 23:56:41,620-[TS] INFO main org.apache.spark.SparkContext - Submitted application: SparkWC
2019-04-07 23:56:41,710 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newfo
2019-04-07 23:56:41,710-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newfo
2019-04-07 23:56:41,713 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newfo
2019-04-07 23:56:41,713-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newfo
2019-04-07 23:56:41,713 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2019-04-07 23:56:41,713-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2019-04-07 23:56:41,717 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2019-04-07 23:56:41,717-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2019-04-07 23:56:41,717 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:56:41,717-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newfo); groups with view permissions: Set(); users  with modify permissions: Set(newfo); groups with modify permissions: Set()
2019-04-07 23:56:42,647 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50252.
2019-04-07 23:56:42,647-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50252.
2019-04-07 23:56:42,678 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2019-04-07 23:56:42,678-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2019-04-07 23:56:42,703 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2019-04-07 23:56:42,703-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2019-04-07 23:56:42,718 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:56:42,718-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-07 23:56:42,718 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2019-04-07 23:56:42,718-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2019-04-07 23:56:42,765 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-f4ee5894-d866-4b80-952c-4c329a0e6c3e
2019-04-07 23:56:42,765-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\newfo\AppData\Local\Temp\blockmgr-f4ee5894-d866-4b80-952c-4c329a0e6c3e
2019-04-07 23:56:42,796 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 888.9 MB
2019-04-07 23:56:42,796-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 888.9 MB
2019-04-07 23:56:42,874 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2019-04-07 23:56:42,874-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2019-04-07 23:56:43,048 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @10268ms
2019-04-07 23:56:43,048-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @10268ms
2019-04-07 23:56:43,120 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2019-04-07 23:56:43,120-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2019-04-07 23:56:43,135 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @10366ms
2019-04-07 23:56:43,135-[TS] INFO main org.spark_project.jetty.server.Server - Started @10366ms
2019-04-07 23:56:43,166 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@7f7dd32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:56:43,166-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@7f7dd32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:56:43,166 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:56:43,166-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2019-04-07 23:56:43,198 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@71c5b236{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@71c5b236{/jobs,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5217f3d0{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5217f3d0{/jobs/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@293bb8a5{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@293bb8a5{/jobs/job,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6e9319f{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,198-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6e9319f{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7bf9b098{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bf9b098{/stages,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@77307458{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77307458{/stages/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@290b1b2e{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@290b1b2e{/stages/stage,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5db4c359{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5db4c359{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@18e7143f{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18e7143f{/stages/pool,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@74cec793{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74cec793{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4f8969b0{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f8969b0{/storage,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@192f2f27{/storage/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c65a5ef{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c65a5ef{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5cc69cfe{/environment/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21c64522{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21c64522{/executors,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@11dee337{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@11dee337{/executors/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@55f3c410{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55f3c410{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@770d4269{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d4269{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,251 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1922e6d{/static,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,251-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1922e6d{/static,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,251 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,251-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2baa8d82{/api,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2baa8d82{/api,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,255-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,259 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:56:43,259-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.113:4040
2019-04-07 23:56:43,467 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2019-04-07 23:56:43,467-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2019-04-07 23:56:43,511 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50261.
2019-04-07 23:56:43,511-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50261.
2019-04-07 23:56:43,511 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.113:50261
2019-04-07 23:56:43,511-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.113:50261
2019-04-07 23:56:43,515 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:56:43,515-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-07 23:56:43,539 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,539-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.113:50261 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.113:50261 with 888.9 MB RAM, BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,555-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.113, 50261, None)
2019-04-07 23:56:43,849 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@138a7441{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,849-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@138a7441{/metrics/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:43,988 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:56:43,988-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse').
2019-04-07 23:56:43,988 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:56:43,988-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/spark-warehouse'.
2019-04-07 23:56:44,003 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1d3e6d34{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d3e6d34{/SQL,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26a94fa5{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26a94fa5{/SQL/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4303b7f0{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4303b7f0{/SQL/execution,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@779de014{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@779de014{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c68a5f8{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:56:44,003-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c68a5f8{/static/sql,null,AVAILABLE,@Spark}
2019-04-07 23:56:45,081 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2019-04-07 23:56:45,081-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2019-04-07 23:56:47,571 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Pruning directories with: 
2019-04-07 23:56:47,571-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pruning directories with: 
2019-04-07 23:56:47,571 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Post-Scan Filters: 
2019-04-07 23:56:47,571-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: 
2019-04-07 23:56:47,571 [main] [org.apache.spark.sql.execution.datasources.FileSourceStrategy] [INFO] - Output Data Schema: struct<value: string>
2019-04-07 23:56:47,571-[TS] INFO main org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<value: string>
2019-04-07 23:56:47,587 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Pushed Filters: 
2019-04-07 23:56:47,587-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Pushed Filters: 
2019-04-07 23:56:50,795 [main] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 2851.1991 ms
2019-04-07 23:56:50,795-[TS] INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 2851.1991 ms
2019-04-07 23:56:51,072 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:56:51,072-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 263.2 KB, free 888.6 MB)
2019-04-07 23:56:51,564 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:56:51,564-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 888.6 MB)
2019-04-07 23:56:51,573 [dispatcher-event-loop-1] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_0_piece0 in memory on 192.168.0.113:50261 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:56:51,573-[TS] INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.0.113:50261 (size: 22.9 KB, free: 888.9 MB)
2019-04-07 23:56:51,604 [main] [org.apache.spark.SparkContext] [INFO] - Created broadcast 0 from rdd at WordCount.scala:11
2019-04-07 23:56:51,604-[TS] INFO main org.apache.spark.SparkContext - Created broadcast 0 from rdd at WordCount.scala:11
2019-04-07 23:56:51,635 [main] [org.apache.spark.sql.execution.FileSourceScanExec] [INFO] - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:56:51,635-[TS] INFO main org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4195774 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-07 23:56:52,449 [main] [org.apache.spark.SparkContext] [INFO] - Starting job: foreach at WordCount.scala:15
2019-04-07 23:56:52,449-[TS] INFO main org.apache.spark.SparkContext - Starting job: foreach at WordCount.scala:15
2019-04-07 23:56:53,626 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Registering RDD 5 (map at WordCount.scala:12)
2019-04-07 23:56:53,626-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (map at WordCount.scala:12)
2019-04-07 23:56:53,626 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Registering RDD 7 (sortBy at WordCount.scala:14)
2019-04-07 23:56:53,626-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Registering RDD 7 (sortBy at WordCount.scala:14)
2019-04-07 23:56:53,642 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Got job 0 (foreach at WordCount.scala:15) with 1 output partitions
2019-04-07 23:56:53,642-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at WordCount.scala:15) with 1 output partitions
2019-04-07 23:56:53,657 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Final stage: ResultStage 2 (foreach at WordCount.scala:15)
2019-04-07 23:56:53,657-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (foreach at WordCount.scala:15)
2019-04-07 23:56:53,657 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Parents of final stage: List(ShuffleMapStage 1)
2019-04-07 23:56:53,657-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2019-04-07 23:56:53,673 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Missing parents: List(ShuffleMapStage 1)
2019-04-07 23:56:53,673-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2019-04-07 23:56:53,688 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:12), which has no missing parents
2019-04-07 23:56:53,688-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:12), which has no missing parents
2019-04-07 23:56:54,182 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_1 stored as values in memory (estimated size 11.4 KB, free 888.6 MB)
2019-04-07 23:56:54,182-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 11.4 KB, free 888.6 MB)
2019-04-07 23:56:54,202 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KB, free 888.6 MB)
2019-04-07 23:56:54,202-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KB, free 888.6 MB)
2019-04-07 23:56:54,210 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_1_piece0 in memory on 192.168.0.113:50261 (size: 6.0 KB, free: 888.9 MB)
2019-04-07 23:56:54,210-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 192.168.0.113:50261 (size: 6.0 KB, free: 888.9 MB)
2019-04-07 23:56:54,214 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 1 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:54,214-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:54,264 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:12) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:54,264-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at map at WordCount.scala:12) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:54,279 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 0.0 with 1 tasks
2019-04-07 23:56:54,279-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
2019-04-07 23:56:54,604 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2019-04-07 23:56:54,604-[TS] INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2019-04-07 23:56:54,651 [Executor task launch worker for task 0] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 0.0 (TID 0)
2019-04-07 23:56:54,651-[TS] INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2019-04-07 23:56:55,184 [Executor task launch worker for task 0] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 102.9762 ms
2019-04-07 23:56:55,184-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 102.9762 ms
2019-04-07 23:56:55,309 [Executor task launch worker for task 0] [org.apache.spark.sql.execution.datasources.FileScanRDD] [INFO] - Reading File path: file:///D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/src/main/resources/wc.txt, range: 0-1470, partition values: [empty row]
2019-04-07 23:56:55,309-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///D:/LocalWorkspace/Idea%20project/Spark_WebLog_Analusis/src/main/resources/wc.txt, range: 0-1470, partition values: [empty row]
2019-04-07 23:56:55,453 [Executor task launch worker for task 0] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 92.2508 ms
2019-04-07 23:56:55,453-[TS] INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 92.2508 ms
2019-04-07 23:56:55,603 [Executor task launch worker for task 0] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 0.0 (TID 0). 1711 bytes result sent to driver
2019-04-07 23:56:55,603-[TS] INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1711 bytes result sent to driver
2019-04-07 23:56:55,618 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 0.0 (TID 0) in 1104 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:55,618-[TS] INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1104 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:55,618 [task-result-getter-0] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-04-07 23:56:55,618-[TS] INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-04-07 23:56:55,618 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ShuffleMapStage 0 (map at WordCount.scala:12) finished in 1.276 s
2019-04-07 23:56:55,618-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (map at WordCount.scala:12) finished in 1.276 s
2019-04-07 23:56:55,634 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - looking for newly runnable stages
2019-04-07 23:56:55,634-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2019-04-07 23:56:55,634 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - running: Set()
2019-04-07 23:56:55,634-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
2019-04-07 23:56:55,634 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-04-07 23:56:55,634-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-04-07 23:56:55,634 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - failed: Set()
2019-04-07 23:56:55,634-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
2019-04-07 23:56:55,634 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:14), which has no missing parents
2019-04-07 23:56:55,634-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:14), which has no missing parents
2019-04-07 23:56:55,650 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 888.6 MB)
2019-04-07 23:56:55,650-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 888.6 MB)
2019-04-07 23:56:55,650 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 888.6 MB)
2019-04-07 23:56:55,650-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 888.6 MB)
2019-04-07 23:56:55,650 [dispatcher-event-loop-0] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_2_piece0 in memory on 192.168.0.113:50261 (size: 2.4 KB, free: 888.9 MB)
2019-04-07 23:56:55,650-[TS] INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on 192.168.0.113:50261 (size: 2.4 KB, free: 888.9 MB)
2019-04-07 23:56:55,665 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 2 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:55,665-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:55,665 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:14) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:55,665-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at sortBy at WordCount.scala:14) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:55,665 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 1.0 with 1 tasks
2019-04-07 23:56:55,665-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
2019-04-07 23:56:55,665 [dispatcher-event-loop-1] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 4610 bytes)
2019-04-07 23:56:55,665-[TS] INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 4610 bytes)
2019-04-07 23:56:55,665 [Executor task launch worker for task 1] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 1.0 (TID 1)
2019-04-07 23:56:55,665-[TS] INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2019-04-07 23:56:55,720 [Executor task launch worker for task 1] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:55,720-[TS] INFO Executor task launch worker for task 1 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:55,720 [Executor task launch worker for task 1] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Started 0 remote fetches in 0 ms
2019-04-07 23:56:55,720-[TS] INFO Executor task launch worker for task 1 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2019-04-07 23:56:55,847 [Executor task launch worker for task 1] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 1.0 (TID 1). 1283 bytes result sent to driver
2019-04-07 23:56:55,847-[TS] INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1283 bytes result sent to driver
2019-04-07 23:56:55,847 [task-result-getter-1] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 1.0 (TID 1) in 182 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:55,847-[TS] INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 182 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:55,847 [task-result-getter-1] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-04-07 23:56:55,847-[TS] INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ShuffleMapStage 1 (sortBy at WordCount.scala:14) finished in 0.182 s
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 1 (sortBy at WordCount.scala:14) finished in 0.182 s
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - looking for newly runnable stages
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - running: Set()
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - waiting: Set(ResultStage 2)
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 2)
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - failed: Set()
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:14), which has no missing parents
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:14), which has no missing parents
2019-04-07 23:56:55,847 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 888.6 MB)
2019-04-07 23:56:55,847-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 888.6 MB)
2019-04-07 23:56:55,863 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2031.0 B, free 888.6 MB)
2019-04-07 23:56:55,863-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2031.0 B, free 888.6 MB)
2019-04-07 23:56:55,863 [dispatcher-event-loop-0] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_3_piece0 in memory on 192.168.0.113:50261 (size: 2031.0 B, free: 888.9 MB)
2019-04-07 23:56:55,863-[TS] INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on 192.168.0.113:50261 (size: 2031.0 B, free: 888.9 MB)
2019-04-07 23:56:55,867 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 3 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:55,867-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:55,867 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:14) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:55,867-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at sortBy at WordCount.scala:14) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:55,867 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 2.0 with 1 tasks
2019-04-07 23:56:55,867-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
2019-04-07 23:56:55,867 [dispatcher-event-loop-1] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:56:55,867-[TS] INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:56:55,867 [Executor task launch worker for task 2] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 2.0 (TID 2)
2019-04-07 23:56:55,867-[TS] INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2019-04-07 23:56:55,867 [Executor task launch worker for task 2] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:55,867-[TS] INFO Executor task launch worker for task 2 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:55,883 [Executor task launch worker for task 2] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Started 0 remote fetches in 16 ms
2019-04-07 23:56:55,883-[TS] INFO Executor task launch worker for task 2 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
2019-04-07 23:56:56,011 [Executor task launch worker for task 2] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 2.0 (TID 2). 1052 bytes result sent to driver
2019-04-07 23:56:56,011-[TS] INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1052 bytes result sent to driver
2019-04-07 23:56:56,015 [task-result-getter-2] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 2.0 (TID 2) in 148 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:56,015-[TS] INFO task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 148 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:56,015 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ResultStage 2 (foreach at WordCount.scala:15) finished in 0.148 s
2019-04-07 23:56:56,015-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (foreach at WordCount.scala:15) finished in 0.148 s
2019-04-07 23:56:56,019 [task-result-getter-2] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-04-07 23:56:56,019-[TS] INFO task-result-getter-2 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-04-07 23:56:56,027 [main] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Job 0 finished: foreach at WordCount.scala:15, took 3.575739 s
2019-04-07 23:56:56,027-[TS] INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at WordCount.scala:15, took 3.575739 s
2019-04-07 23:56:56,067 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: wc
2019-04-07 23:56:56,067-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: wc
2019-04-07 23:56:56,384 [main] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 20.891 ms
2019-04-07 23:56:56,384-[TS] INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.891 ms
2019-04-07 23:56:56,400 [main] [org.apache.spark.SparkContext] [INFO] - Starting job: show at WordCount.scala:22
2019-04-07 23:56:56,400-[TS] INFO main org.apache.spark.SparkContext - Starting job: show at WordCount.scala:22
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.MapOutputTrackerMaster] [INFO] - Size of output statuses for shuffle 1 is 149 bytes
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 1 is 149 bytes
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.MapOutputTrackerMaster] [INFO] - Size of output statuses for shuffle 0 is 149 bytes
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 149 bytes
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Got job 1 (show at WordCount.scala:22) with 1 output partitions
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (show at WordCount.scala:22) with 1 output partitions
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Final stage: ResultStage 5 (show at WordCount.scala:22)
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at WordCount.scala:22)
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Parents of final stage: List(ShuffleMapStage 4)
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Missing parents: List()
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2019-04-07 23:56:56,400 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting ResultStage 5 (MapPartitionsRDD[13] at show at WordCount.scala:22), which has no missing parents
2019-04-07 23:56:56,400-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[13] at show at WordCount.scala:22), which has no missing parents
2019-04-07 23:56:56,415 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_4 stored as values in memory (estimated size 10.3 KB, free 888.6 MB)
2019-04-07 23:56:56,415-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 10.3 KB, free 888.6 MB)
2019-04-07 23:56:56,415 [dag-scheduler-event-loop] [org.apache.spark.storage.memory.MemoryStore] [INFO] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KB, free 888.6 MB)
2019-04-07 23:56:56,415-[TS] INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KB, free 888.6 MB)
2019-04-07 23:56:56,415 [dispatcher-event-loop-0] [org.apache.spark.storage.BlockManagerInfo] [INFO] - Added broadcast_4_piece0 in memory on 192.168.0.113:50261 (size: 5.4 KB, free: 888.9 MB)
2019-04-07 23:56:56,415-[TS] INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on 192.168.0.113:50261 (size: 5.4 KB, free: 888.9 MB)
2019-04-07 23:56:56,415 [dag-scheduler-event-loop] [org.apache.spark.SparkContext] [INFO] - Created broadcast 4 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:56,415-[TS] INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1015
2019-04-07 23:56:56,415 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at show at WordCount.scala:22) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:56,415-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at show at WordCount.scala:22) (first 15 tasks are for partitions Vector(0))
2019-04-07 23:56:56,415 [dag-scheduler-event-loop] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Adding task set 5.0 with 1 tasks
2019-04-07 23:56:56,415-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks
2019-04-07 23:56:56,432 [dispatcher-event-loop-1] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Starting task 0.0 in stage 5.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:56:56,432-[TS] INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2019-04-07 23:56:56,432 [Executor task launch worker for task 3] [org.apache.spark.executor.Executor] [INFO] - Running task 0.0 in stage 5.0 (TID 3)
2019-04-07 23:56:56,432-[TS] INFO Executor task launch worker for task 3 org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 3)
2019-04-07 23:56:56,440 [Executor task launch worker for task 3] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:56,440-[TS] INFO Executor task launch worker for task 3 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
2019-04-07 23:56:56,440 [Executor task launch worker for task 3] [org.apache.spark.storage.ShuffleBlockFetcherIterator] [INFO] - Started 0 remote fetches in 0 ms
2019-04-07 23:56:56,440-[TS] INFO Executor task launch worker for task 3 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2019-04-07 23:56:56,456 [Executor task launch worker for task 3] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 12.2966 ms
2019-04-07 23:56:56,456-[TS] INFO Executor task launch worker for task 3 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.2966 ms
2019-04-07 23:56:56,534 [Executor task launch worker for task 3] [org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator] [INFO] - Code generated in 53.4172 ms
2019-04-07 23:56:56,534-[TS] INFO Executor task launch worker for task 3 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 53.4172 ms
2019-04-07 23:56:56,534 [Executor task launch worker for task 3] [org.apache.spark.executor.Executor] [INFO] - Finished task 0.0 in stage 5.0 (TID 3). 1748 bytes result sent to driver
2019-04-07 23:56:56,534-[TS] INFO Executor task launch worker for task 3 org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 3). 1748 bytes result sent to driver
2019-04-07 23:56:56,534 [task-result-getter-3] [org.apache.spark.scheduler.TaskSetManager] [INFO] - Finished task 0.0 in stage 5.0 (TID 3) in 102 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:56,534-[TS] INFO task-result-getter-3 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 3) in 102 ms on localhost (executor driver) (1/1)
2019-04-07 23:56:56,534 [task-result-getter-3] [org.apache.spark.scheduler.TaskSchedulerImpl] [INFO] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-04-07 23:56:56,534-[TS] INFO task-result-getter-3 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-04-07 23:56:56,534 [dag-scheduler-event-loop] [org.apache.spark.scheduler.DAGScheduler] [INFO] - ResultStage 5 (show at WordCount.scala:22) finished in 0.103 s
2019-04-07 23:56:56,534-[TS] INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (show at WordCount.scala:22) finished in 0.103 s
2019-04-07 23:56:56,534 [main] [org.apache.spark.scheduler.DAGScheduler] [INFO] - Job 1 finished: show at WordCount.scala:22, took 0.146601 s
2019-04-07 23:56:56,534-[TS] INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 finished: show at WordCount.scala:22, took 0.146601 s
2019-04-07 23:56:56,565 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Invoking stop() from shutdown hook
2019-04-07 23:56:56,565-[TS] INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2019-04-07 23:56:56,581 [Thread-2] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Stopped Spark@7f7dd32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:56:56,581-[TS] INFO Thread-2 org.spark_project.jetty.server.AbstractConnector - Stopped Spark@7f7dd32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-07 23:56:56,581 [Thread-2] [org.apache.spark.ui.SparkUI] [INFO] - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:56:56,581-[TS] INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.0.113:4040
2019-04-07 23:56:56,597 [dispatcher-event-loop-2] [org.apache.spark.MapOutputTrackerMasterEndpoint] [INFO] - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:56:56,597-[TS] INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2019-04-07 23:56:56,612 [Thread-2] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore cleared
2019-04-07 23:56:56,612-[TS] INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2019-04-07 23:56:56,612 [Thread-2] [org.apache.spark.storage.BlockManager] [INFO] - BlockManager stopped
2019-04-07 23:56:56,612-[TS] INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
2019-04-07 23:56:56,628 [Thread-2] [org.apache.spark.storage.BlockManagerMaster] [INFO] - BlockManagerMaster stopped
2019-04-07 23:56:56,628-[TS] INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2019-04-07 23:56:56,628 [dispatcher-event-loop-3] [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] [INFO] - OutputCommitCoordinator stopped!
2019-04-07 23:56:56,628-[TS] INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2019-04-07 23:56:56,628 [Thread-2] [org.apache.spark.SparkContext] [INFO] - Successfully stopped SparkContext
2019-04-07 23:56:56,628-[TS] INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
2019-04-07 23:56:56,628 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Shutdown hook called
2019-04-07 23:56:56,628-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2019-04-07 23:56:56,628 [Thread-2] [org.apache.spark.util.ShutdownHookManager] [INFO] - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-90b49c57-42eb-42ab-9b58-adc30cff9631
2019-04-07 23:56:56,628-[TS] INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\newfo\AppData\Local\Temp\spark-90b49c57-42eb-42ab-9b58-adc30cff9631
